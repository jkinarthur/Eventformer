{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Eventformer: Frame-Free Vision Transformer\n",
        "\n",
        "Run on Google Colab with T4 GPU. Go to **Runtime > Change runtime type > T4 GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Check GPU\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Clone repository\n",
        "!rm -rf /content/Eventformer\n",
        "!git clone https://github.com/jkinarthur/Eventformer.git\n",
        "%cd /content/Eventformer/code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Install dependencies\n",
        "!pip install -q einops timm scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Setup imports\n",
        "import sys\n",
        "sys.path.insert(0, '/content/Eventformer/code')\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "\n",
        "# Import models\n",
        "from models import eventformer_tiny, EventformerForClassification\n",
        "from models.ctpe import ContinuousTimePositionalEncoding\n",
        "from models.paaa import PolarityAwareAsymmetricAttention\n",
        "from models.asna import ASNABlock\n",
        "\n",
        "print('All imports successful!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Test Model\n",
        "model = eventformer_tiny().to(device)\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Parameters:', f'{num_params:,}')\n",
        "\n",
        "# Test forward pass\n",
        "B, N = 4, 2048\n",
        "coords = torch.rand(B, N, 2, device=device) * 346\n",
        "times = torch.rand(B, N, device=device).sort(dim=1)[0]\n",
        "pols = torch.randint(0, 2, (B, N), device=device).float() * 2 - 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model(coords, times, pols)\n",
        "\n",
        "print('Output shape:', out[0].shape)\n",
        "print('Model test passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Generate Publication Figures\n",
        "import os\n",
        "os.makedirs('figures', exist_ok=True)\n",
        "\n",
        "from visualize import generate_all_figures\n",
        "figures = generate_all_figures(output_dir='figures')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Display Figures\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "figure_files = [\n",
        "    'training_curves.png',\n",
        "    'ablation_all_datasets.png',\n",
        "    'ablation_detailed.png',\n",
        "    'comparison_accuracy_vs_flops.png',\n",
        "    'comparison_accuracy_vs_params.png',\n",
        "    'velocity_stratification.png',\n",
        "    'delta_t_sensitivity.png',\n",
        "    'event_cloud_visualization.png',\n",
        "    'fps_comparison.png'\n",
        "]\n",
        "\n",
        "for fname in figure_files:\n",
        "    fpath = os.path.join('figures', fname)\n",
        "    if os.path.exists(fpath):\n",
        "        print(f'\\n--- {fname} ---')\n",
        "        display(Image(filename=fpath, width=700))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Show LaTeX Tables\n",
        "print('='*60)\n",
        "print('LATEX TABLES')\n",
        "print('='*60)\n",
        "\n",
        "if os.path.exists('figures/all_tables.tex'):\n",
        "    with open('figures/all_tables.tex', 'r') as f:\n",
        "        print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Download all figures\n",
        "!zip -r eventformer_results.zip figures/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('eventformer_results.zip')\n",
        "print('Download ready!')"
      ]
    }
  ]
}