{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb48099c",
   "metadata": {},
   "source": [
    "# ðŸš€ Eventformer: Frame-Free Vision Transformer for Event Cameras\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/Eventformer/blob/main/Eventformer_Colab.ipynb)\n",
    "\n",
    "This notebook allows you to train and evaluate Eventformer on Google Colab with free GPU.\n",
    "\n",
    "**Key Components:**\n",
    "- CTPE: Continuous-Time Positional Encoding\n",
    "- PAAA: Polarity-Aware Asymmetric Attention\n",
    "- ASNA: Adaptive Spatiotemporal Neighborhood Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217828f6",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (replace YOUR_USERNAME with your GitHub username)\n",
    "!git clone https://github.com/YOUR_USERNAME/Eventformer.git\n",
    "%cd Eventformer/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3896ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q einops timm h5py tensorboard seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576ca64",
   "metadata": {},
   "source": [
    "## 2. Test Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all component tests\n",
    "!python main.py --mode test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720204c",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "\n",
    "Choose the dataset you want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories\n",
    "!mkdir -p ../data/ncaltech101\n",
    "!mkdir -p ../data/dvs128_gesture\n",
    "!mkdir -p ../data/gen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1281b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download N-Caltech101 (recommended for quick testing)\n",
    "# Note: You may need to manually download from:\n",
    "# https://www.garrickorchard.com/datasets/n-caltech101\n",
    "\n",
    "# If you have the dataset on Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp -r /content/drive/MyDrive/datasets/ncaltech101/* ../data/ncaltech101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - for saving checkpoints and loading data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory in Drive\n",
    "!mkdir -p /content/drive/MyDrive/Eventformer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b0986",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "Train Eventformer on your chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f279c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with synthetic data (no download needed)\n",
    "# The code generates synthetic events automatically when real data is not found\n",
    "\n",
    "!python train.py \\\n",
    "    --dataset ncaltech101 \\\n",
    "    --data_root ../data \\\n",
    "    --model tiny \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 16 \\\n",
    "    --num_events 2048 \\\n",
    "    --output_dir ../outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training (when you have real data)\n",
    "!python train.py \\\n",
    "    --dataset ncaltech101 \\\n",
    "    --data_root ../data \\\n",
    "    --model small \\\n",
    "    --epochs 100 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_events 4096 \\\n",
    "    --lr 1e-4 \\\n",
    "    --output_dir /content/drive/MyDrive/Eventformer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6250d",
   "metadata": {},
   "source": [
    "## 5. Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ablation study to evaluate component contributions\n",
    "!python ablation.py \\\n",
    "    --dataset ncaltech101 \\\n",
    "    --data_root ../data \\\n",
    "    --model_size tiny \\\n",
    "    --epochs 20 \\\n",
    "    --num_runs 3 \\\n",
    "    --configs full no_ctpe no_paaa no_asna \\\n",
    "    --output_dir ../ablation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a6342",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81672465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "# Replace with your actual checkpoint path\n",
    "!python evaluate.py \\\n",
    "    --checkpoint ../outputs/best_model.pth \\\n",
    "    --dataset ncaltech101 \\\n",
    "    --data_root ../data \\\n",
    "    --benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c99df9",
   "metadata": {},
   "source": [
    "## 7. Generate Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate publication-quality figures\n",
    "!python visualize.py --output_dir ../figures\n",
    "\n",
    "# Display generated figures\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "figures_dir = '../figures'\n",
    "if os.path.exists(figures_dir):\n",
    "    for fig in os.listdir(figures_dir):\n",
    "        if fig.endswith('.png'):\n",
    "            print(f\"\\n{fig}:\")\n",
    "            display(Image(os.path.join(figures_dir, fig)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e1e88",
   "metadata": {},
   "source": [
    "## 8. Interactive Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "from models import eventformer_tiny, eventformer_small, EventformerForClassification\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = eventformer_tiny().to(device)\n",
    "\n",
    "# Print model info\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: Eventformer-Tiny\")\n",
    "print(f\"Parameters: {num_params:,} ({num_params/1e6:.2f}M)\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Test forward pass\n",
    "B, N = 4, 4096\n",
    "coords = torch.rand(B, N, 2).to(device) * torch.tensor([346, 260]).to(device)\n",
    "times = torch.rand(B, N).to(device).sort(dim=1)[0]\n",
    "polarities = (torch.randint(0, 2, (B, N)).float() * 2 - 1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features, out_coords, out_times, out_pols = model(coords, times, polarities)\n",
    "\n",
    "print(f\"\\nInput: {N} events per sample\")\n",
    "print(f\"Output: {features.shape[1]} events, {features.shape[2]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ab889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed benchmark\n",
    "import time\n",
    "\n",
    "model.eval()\n",
    "num_iters = 100\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(coords, times, polarities)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Benchmark\n",
    "start = time.perf_counter()\n",
    "for _ in range(num_iters):\n",
    "    with torch.no_grad():\n",
    "        _ = model(coords, times, polarities)\n",
    "torch.cuda.synchronize()\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\nSpeed Benchmark:\")\n",
    "print(f\"  Batch size: {B}\")\n",
    "print(f\"  Events: {N}\")\n",
    "print(f\"  Time per batch: {elapsed/num_iters*1000:.2f} ms\")\n",
    "print(f\"  Throughput: {B*num_iters/elapsed:.1f} samples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cda2f0",
   "metadata": {},
   "source": [
    "## 9. Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79606e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to Google Drive\n",
    "!cp -r ../outputs/* /content/drive/MyDrive/Eventformer_outputs/ 2>/dev/null || echo \"No outputs to copy\"\n",
    "!cp -r ../ablation_results/* /content/drive/MyDrive/Eventformer_outputs/ 2>/dev/null || echo \"No ablation results to copy\"\n",
    "!cp -r ../figures/* /content/drive/MyDrive/Eventformer_outputs/ 2>/dev/null || echo \"No figures to copy\"\n",
    "\n",
    "print(\"Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1a2bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**GPU Runtime:**\n",
    "- Go to Runtime â†’ Change runtime type â†’ Select GPU (T4 is free, A100 for Colab Pro)\n",
    "\n",
    "**Dataset Download:**\n",
    "- N-Caltech101: https://www.garrickorchard.com/datasets/n-caltech101\n",
    "- DVS128 Gesture: https://research.ibm.com/interactive/dvsgesture/\n",
    "- GEN1: https://www.prophesee.ai/2020/01/24/prophesee-gen1-automotive-detection-dataset/\n",
    "\n",
    "**Memory Issues:**\n",
    "- Reduce `--batch_size` or `--num_events` if you run out of GPU memory\n",
    "- Use `--model tiny` instead of larger models\n",
    "\n",
    "**Save Checkpoints:**\n",
    "- Mount Google Drive to save checkpoints between sessions\n",
    "- Use `--output_dir /content/drive/MyDrive/Eventformer_outputs`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
